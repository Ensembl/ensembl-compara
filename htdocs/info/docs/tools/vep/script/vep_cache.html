<html>
<head>
<title>Caches and databases</title>
<meta name="order" content="4" />
</head>

<body>
    
<div>
	
	<div style="float:right"><img src="/img/vep_logo.png"/></div>
	
	<h1 id="top"><span style="color:#006">Variant Effect Predictor</span> <img src="/i/16/database.png"> <span style="color:#666">Caches and databases</span></h1>
	<hr/>	
	
	<p> The VEP script can use a variety of data sources to retrieve transcript
	information that is used to predict consequence types. </p>
    
    <p> Using a local cache is the most efficient way to use the VEP; we would
    encourage users to use the cache wherever possible. Caches are easy to
    download and set up using the <a
    href="vep_download.html#installer">installer</a>. Follow the <a
    href="vep_tutorial.html">tutorial</a> for a simple guide.</p>
	
	
	<h2 id="cache">Using the cache</h2>
	
    <p> Using the cache (<a href="vep_options.html#opt_cache">--cache</a>) is
    the fastest and most efficient way to use the VEP script, as in most cases
    only a single initial network connection is made and most data is read from
    local disk. Use <a href="#offline">offline</a> mode eliminate all network
    connections.</p>
	
    <p> Cache files are compressed using the gzip utility. By default zcat is
    used to decompress the files, although gzcat or gzip itself can be used to
    decompress also - you must have one of these utilities installed in your
    path to use the cache. Use <a
    href="vep_options.html#opt_compress">--compress [command]</a> to change the
    default.</p>
	
	<hr/>
	<h2 id="pre">Pre-built caches</h2>
	
	<p> The easiest solution is to download a pre-built cache for your species;
	this eliminates the need to connect to the database while the script is
	running (except when using <a href="#limitations">certain options</a>).
	Cache files can either be downloaded and unpacked as described here, or
	automatically downloaded and configured using the <a
	href="vep_download.html#installer">installer script</a>. <p>
    
    <p> Cache files for popular species: </p>
    
    <ul>
        <li><a href="ftp://ftp.ensembl.org/pub/release-[[SPECIESDEFS::ENSEMBL_VERSION]]/variation/VEP/homo_sapiens_vep_[[SPECIESDEFS::ENSEMBL_VERSION]].tar.gz">Human <i>(Homo sapiens)</i></a></li>
        <li><a href="ftp://ftp.ensembl.org/pub/release-[[SPECIESDEFS::ENSEMBL_VERSION]]/variation/VEP/mus_musculus_vep_[[SPECIESDEFS::ENSEMBL_VERSION]].tar.gz">Mouse <i>(Mus musculus)</i></a></li>
        <li><a href="ftp://ftp.ensembl.org/pub/release-[[SPECIESDEFS::ENSEMBL_VERSION]]/variation/VEP/danio_rerio_vep_[[SPECIESDEFS::ENSEMBL_VERSION]].tar.gz">Zebrafish <i>(Danio rerio)</i></a></li>
    </ul>
    
    <p> Other species: </p>
    
    <ul>
        <li><a href="ftp://ftp.ensembl.org/pub/current_variation/VEP/">Vertebrates</a></li>
        <li><a href="ftp://ftp.ensemblgenomes.org/pub/bacteria/current/vep/">Bacteria</a></li>
        <li><a href="ftp://ftp.ensemblgenomes.org/pub/fungi/current/vep/">Fungi</a></li>
        <li><a href="ftp://ftp.ensemblgenomes.org/pub/metazoa/current/vep/">Metazoa</a></li>
        <li><a href="ftp://ftp.ensemblgenomes.org/pub/plants/current/vep/">Plants</a></li>
        <li><a href="ftp://ftp.ensemblgenomes.org/pub/protists/current/vep/">Protists</a></li>
    </ul>
    
    <h4>Instructions for use</h4>
    
	<ol>
		<li>
			Download the archive file for your species</a>
		</li>
		<li>
			Extract the archive in your cache directory. By default the VEP uses
			$HOME/.vep/ as the cache directory, where $HOME is your UNIX home
			directory.
			<pre class="code">mv homo_sapiens_vep_[[SPECIESDEFS::ENSEMBL_VERSION]].tar.gz ~/.vep/
cd ~/.vep/
tar xfz homo_sapiens_vep_[[SPECIESDEFS::ENSEMBL_VERSION]].tar.gz</pre>
		</li>
		<li>
			Run the VEP with the <a href="vep_options.html#opt_cache">--cache</a> option
		</li>
	</ol>
	
	<p> Caches for several species, and indeed different Ensembl releases of the
	same species, can be stored in the same cache base directory. The files are
	stored in the following directory hierarchy: $HOME -> .vep -> species ->
	version -> chromosome </p>
	
	<p> If a pre-built cache does not exist for your species, please contact us
	at <a href="mailto:dev@ensembl.org">dev@ensembl.org</a> and we will
	endeavour to add your species to the list of downloads. </p>
	
	<p> It is also possible to build your own <a href="#gtf">cache from a GTF
	file</a> and a FASTA file. </p>
	
	<p> It is possible to use any combination of cache and database; when using
	the cache, the cache will take preference, with the database being used when
	the relevant data is not found in the cache. </p>
	
	
	<hr/>
	<h2 id="gtf">Building a cache from a GTF file</h2>
	
	<p> For species that don't have a publicly available cache, or even an
	Ensembl core database, it is possible to build a VEP cache using the
	gtf2vep.pl script included alongside the main script. This requires a GTF
	file and a FASTA file containing the reference sequence for the same
	species. The GTF file have its features sorted in chromosomal order, and
	must contain the following entry types and data: </p>
	
	<ul>
		<li>"exon" feature lines with have "transcript_id", "gene_id" and
		"exon_number" in the description field</li>
		<li>"CDS" feature lines must correspond to coding exons, with
		"transcript_id" and "exon_number" populated in the description
		field, and the "frame" column populated with the read frame of the
		exon</li>
		<li>the "source" column of the GTF should indicate the biotype of the
		exon/CDS - this should be "protein_coding" for protein coding
		transcripts</li>
	</ul>
	
	<p> For examples of these, see the GTF files made available by Ensembl on
	the <a href="/info/data/ftp/index.html">Downloads</a> page </p>
	
	<p> The FASTA file should contain sequence for all values of the seqname
	column in the GTF file. The first time you run the script, the
	Bio::DB::Fasta module will create an index for the file that allows rapid
	random access to the sequences corresponding to the transcripts described in
	the GTF file; this may take a few minutes to create. </p>
	
	<p> The script is run as follows: </p>
	
	<pre class="code">perl gtf2vep.pl -i my_species_genes.gtf -f my_species_seq.fa -d [[SPECIESDEFS::ENSEMBL_VERSION]] -s my_species
perl variant_effect_predictor.pl -offline -i my_species_variants.vcf -s my_species</pre>
	
	<p> By default the cache is created in $HOME/.vep/[species]/[version]/ - to
	change this root directory, use <a href="vep_options.html#opt_dir">--dir</a>. </p>
	
	<p> This process takes around 15-20 minutes for human (including the time
	taken to index the FASTA file). Note that caches created in this way can
	only be used in <a href="#offline">offline mode</a>.
	
	
	<hr/>
	<h2 id="fasta">Using FASTA files</h2>
	
    <p> By pointing the VEP to a FASTA file (or directory containing several
    files), it is possible to retrieve reference sequence locally when using
    <a href="vep_options.html#opt_cache">--cache</a> or <a
    href="vep_options.html#opt_offline">--offline</a>. This enables the VEP to
    retrieve HGVS notations (<a href="vep_options.html#opt_hgvs">--hgvs</a>) and
    check the reference sequence given in input data (<a
    href="vep_options.html#opt_check_ref">--check_ref</a>) without accessing a
    database. </p>
    
    <p> FASTA files can be set up using the <a
    href="vep_download.html#installer">installer</a>; files set up using the
    installer are automatically detected by the VEP when using <a
    href="vep_options.html#opt_cache">--cache</a> or <a
    href="vep_options.html#opt_offline">--offline</a>; you should not need to
    use <a href="vep_options.html#opt_fasta">--fasta</a> to manually specify
    them. </p>
	
	<p> To enable this the VEP uses the <a
	rel="external" href="http://search.cpan.org/~cjfields/BioPerl-1.6.901/Bio/DB/Fasta.pm"
	target="_blank">Bio::DB::Fasta</a> module. The first time you run the script
	with a specific FASTA file, an index will be built. This can take a few
	minutes, depending on the size of the FASTA file and the speed of your
	system. On subsequent runs the index does not need to be rebuilt (if the
	FASTA file has been modified, the VEP will force a rebuild of the index).
	</p>
	
	<p> Ensembl provides suitable reference FASTA files as downloads from its
	FTP server. See the <a href="/info/data/ftp/index.html">Downloads</a> page
	for details. In most cases it is best to download the single large
	"primary_assembly" file for your species. You should use the unmasked
	(without "_rm" or "_sm" in the name) sequences. Note that the VEP requires
	that the file be unzipped to run; when unzipped these files can be very
	large (25GB for human). An example set of commands for setting up the data
	for human follows: </p>
	
	<pre class="code">wget ftp://ftp.ensembl.org/pub/release-[[SPECIESDEFS::ENSEMBL_VERSION]]/fasta/homo_sapiens/dna/Homo_sapiens.GRCh27.[[SPECIESDEFS::ENSEMBL_VERSION]].dna.primary_assembly.fa.gz
gzip -d Homo_sapiens.GRCh27.[[SPECIESDEFS::ENSEMBL_VERSION]].dna.primary_assembly.fa.gz
perl variant_effect_predictor.pl -i input.vcf --offline --hgvs --fasta Homo_sapiens.GRCh27.[[SPECIESDEFS::ENSEMBL_VERSION]].dna.primary_assembly.fa</pre>
	
	
	<hr/>
	<h2 id="convert">Convert with tabix</h2>
    
    <p> For users with <a rel="external" href="http://samtools.sourceforge.net/tabix.shtml"
    target="_blank">tabix</a> installed on their systems, the speed of
    retrieving existing co-located variants can be greatly improved by
    converting the cache files using the supplied script, convert_cache.pl. This
    replaces the plain-text, chunked variant dumps with a single tabix-indexed
    file per chromosome. The script is simple to run: </p>
    
    <pre class="code">perl convert_cache.pl -species [species] -version [vep_version]</pre>
    
    <p> To convert all species and all versions, use "all": </p>
    
    <pre class="code">perl convert_cache.pl -species all -version all</pre>
    
    <p> A full description of the options can be seen using <b>--help</b>. When complete, the VEP should
    automatically detect the converted cache and use this in place. Note that
    tabix and bgzip must be installed on your system to use a converted cache.
    </p>
    
	<hr/>
	<h2 id="limitations">Limitations of the cache</h2>
	
	<p> The cache stores the following information: </p>
	
	<ul>
		<li>Transcript location, sequence, exons and other attributes</li>
		<li>Gene, protein and HGNC identifiers for each transcript (where
		applicable)</li>
		<li>Location and alleles of existing variations</li>
		<li>Regulatory regions</li>
		<li>Predictions and scores for SIFT, PolyPhen</li>
	</ul>
	
	<p> It does not store any information pertaining to, and therefore cannot be
	used for, the following: </p>
	
	<ul>
		<li>Frequency filtering of input (<a href="vep_options.html#opt_check_frequency">--check_frequency</a>) on populations not included in the cache. The human cache currently includes frequency data for the combined 1000 Genomes phase 1 population (ALL), the continental level populations (AFR, AMR, ASN, EUR), and the two NHLBI-ESP populations (AA, EA). It does <b>not</b> contain frequencies for national level (e.g. CEU, YRI) populations.</li>
		<li>HGVS names (<a href="vep_options.html#opt_hgvs">--hgvs</a>) - to retrieve these you must additionally point
		to a FASTA file containing the reference sequence for your species
		(<a href="vep_options.html#opt_fasta">--fasta</a>)</li>
		<li>Using HGVS notation as input (<a href="vep_options.html#opt_format">--format hgvs</a>)</li>
		<li>Using variant identifiers as input (<a href="vep_options.html#opt_format">--format id</a>)</li>
		<li>Finding overlapping structural variants (<a href="vep_options.html#opt_check_sv">--check_sv</a>)</li>
	</ul>
	
    <p> Enabling one of these options with <a href="vep_options.html#opt_cache">--cache</a> will cause the script
    to warn you in its status output with something like the following: </p>
	
	<pre class="code"> 2011-06-16 16:24:51 - INFO: Database will be accessed when using --hgvs </pre>
    
    
	<hr/>
	<h2 id="privacy">Data privacy</h2>
	
	<p> When using the public database servers, the VEP script requests
	transcript and variation data that overlap the loci in your input file. As
	such, these coordinates are transmitted over the network to a public server,
	which may not be suitable for those with sensitive or private data. Users
	should note that <b>only</b> the coordinates are transmitted to the server;
	no other information is sent. </p>
	
	<p> By using a full downloaded cache (preferably in <a
	href="#offline">offline mode</a>) or a local database, it is possible to
	avoid completely any network connections to public servers, thus preserving
	absolutely the privacy of your data. </p>
	
	
	<hr/>
	<h2 id="offline">Offline mode</h2>
	
	<p> It is possible to run the VEP in a offline mode that does not use the
	database, and does not require a standard installation of the Ensembl API.
    This means users require only perl (version 5.8 or greater) and the either
    zcat, gzcat or gzip utilities. To enable this mode, use the flag
    <a href="vep_options.html#opt_offline">--offline</a>. </p>
	
    <p> The simplest way to set up your system is to use the <a
    href="vep_download.html#installer">installer script</a>, INSTALL.pl. This
    will download the required dependencies to your system, and download and set
    up any cache files that you require.</p>
	
    <p> The <a href="#limitations">limitations</a> described above apply
    absolutely when using offline mode. For example, if you specify <a
    href="vep_options.html#opt_offline">--offline</a> and <a
    href="vep_options.html#opt_check_sv">--check_sv</a>, the script will report
    an error and refuse to run. </p>
	
    <p> All other features, including the ability to use <a
    href="vep_custom.html">custom annotations</a> and <a
    href="vep_plugins.html">plugins</a>, are accessible in offline mode. </p>
	
	
	<hr/>
	<h2 id="public">Public database servers</h2>
	
    <p> By default, the script is configured to connect to Ensembl's public
    MySQL instance at ensembldb.ensembl.org. For users in the US (or for any
    user geographically closer to the East coast of the USA than to Ensembl's
    data centre in Cambridge, UK), a mirror server is available at
    useastdb.ensembl.org. To use the mirror, use the flag <a
    href="vep_options.html#opt_host">--host</a> useastdb.ensembl.org </p>
	
    <p> Users of Ensembl Genomes species (e.g. plants, fungi, microbes) should
    use their public MySQL instance; the connection parameters for this can be
    automatically loaded by using the flag <a
    href="vep_options.html#opt_genomes">--genomes</a> </p>
	
	<p> Users with small data sets (100s of variants) should find using the
	default connection settings adequate. Those with larger data sets, or those
	who wish to use the script in a batch manner, should consider one of the
	alternatives below. </p>
	
	
	
	<hr/>
	<h2 id="local">Using a local database</h2>
	
    <p> It is possible to set up a local MySQL mirror with the databases for
    your species of interest installed. For instructions on installing a local
    mirror, see <a href="/info/docs/webcode/install/ensembl-data.html"
    target="_blank">here</a>. You will need a MySQL server that you can connect
    to from the machine where you will run the script (this can be the same
    machine). For most of the functionality of the VEP, you will only need the
    Core database (e.g. homo_sapiens_core_[[SPECIESDEFS::ENSEMBL_VERSION]]_37)
    installed. In order to find co-located variations or to use SIFT or
    PolyPhen, it is also necessary to install the relevant variation database
    (e.g. homo_sapiens_variation_[[SPECIESDEFS::ENSEMBL_VERSION]]_37). </p>
	
	<p> Note that unless you have custom data to insert in the database, in most
	cases it will be much more efficient to use a <a href="#pre">pre-built
	cache</a> in place of a local database. </p>
	
    <p> To connect to your mirror, you can either set the connection parameters
    using <a href="vep_options.html#opt_host">--host</a>, <a
    href="vep_options.html#opt_port">--port</a>, <a
    href="vep_options.html#opt_user">--user</a> and <a
    href="vep_options.html#opt_password">--password</a>, or use a registry file.
    Registry files contain all the connection parameters for your database, as
    well as any species aliases you wish to set up: </p>
	
	<pre class="code">
use Bio::EnsEMBL::DBSQL::DBAdaptor;
use Bio::EnsEMBL::Variation::DBSQL::DBAdaptor;
use Bio::EnsEMBL::Registry;

Bio::EnsEMBL::DBSQL::DBAdaptor->new(
  '-species' => "Homo_sapiens",
  '-group'   => "core",
  '-port'    => 5306,
  '-host'    => 'ensembldb.ensembl.org',
  '-user'    => 'anonymous',
  '-pass'    => '',
  '-dbname'  => 'homo_sapiens_core_[[SPECIESDEFS::ENSEMBL_VERSION]]_37'
);

Bio::EnsEMBL::Variation::DBSQL::DBAdaptor->new(
  '-species' => "Homo_sapiens",
  '-group'   => "variation",
  '-port'    => 5306,
  '-host'    => 'ensembldb.ensembl.org',
  '-user'    => 'anonymous',
  '-pass'    => '',
  '-dbname'  => 'homo_sapiens_variation_[[SPECIESDEFS::ENSEMBL_VERSION]]_37'
);

Bio::EnsEMBL::Registry->add_alias("Homo_sapiens","human");
	</pre>
	
	<p> For more information on the registry and registry files, see <a
	href="/info/docs/api/registry.html" target="_blank">here</a>. </p>
	
	
	<hr/>
	<h2 id="build">Building your own cache</h2>
	
	<p> It is possible to build your own cache using the VEP script. <span
	style="color:red;">You should <b>NOT</b> use this command when connected to
	the public MySQL instances</span> - the process takes a long time, meaning
	the connection can break unexpectedly and you will be violating Ensembl's
	reasonable use policy on the public servers. You should either download one
	of the pre-built caches, or create a <a href="#local">local</a> copy of your
	database of interest to build the cache from. </p>
	
	<p> You may wish to build a full cache if you have a custom Ensembl database
	with data not found on the public servers, or you may wish to create a
	minimal cache covering only a certain set of chromosome regions. Cache files
	are compressed using the gzip utility; this must be installed in your path
	to write cache files. </p>
	
    <p> To build a cache "on-the-fly", use the <a
    href="vep_options.html#opt_cache">--cache</a> and <a
    href="vep_options.html#opt_write_cache">--write_cache</a> flags when you run
    the VEP with your input. Only cache files overlapping your input variants
    will be created; the next time you run the script with this cache, the data
    will be read from the cache instead of the database. Any data not found in
    the cache will be read from the database (and then written to the cache if
    <a href="vep_options.html#opt_write_cache">--write_cache</a> is enabled). If
    your data covers a relatively small proportion of your genome of interest
    (for example, a few genes of interest), it can be OK to use the public MySQL
    servers when building a partial cache. </p>
	
	<pre class="code">perl variant_effect_predictor.pl -cache -dir /my/cache/dir/ -write_cache -i input.txt</pre>
	
    <p> To build a cache from scratch, use the flag <a
    href="vep_options.html#opt_build">--build all</a> or e.g. <a
    href="vep_options.html#opt_build">--build 1-5,X</a> to build just a subset
    of chromosomes. You do not need to specify any of the usual input options
    when building a cache:</p>
	
	<pre class="code">perl variant_effect_predictor.pl -host dbhost -user username -pass password -port 3306 -build 21 -dir /my/cache/dir/</pre>
	
	
	<table class="ss" style="width:75%;">
		<tr>
			<th>Normal mode</th>
			<th>Cache mode</th>
			<th>Build mode</th>
		</tr>
		<tr>
			<td><a href="/img/vep_cache_normal.png"><img src="/img/vep_cache_normal_thumb.png" /></a></td>
			<td><a href="/img/vep_cache_cache.png"><img src="/img/vep_cache_cache_thumb.png" /></a></td>
			<td valign="middle"><a href="/img/vep_cache_build.png"><img src="/img/vep_cache_build_thumb.png" /></a></td>
		</tr>
	</table>
	
	<hr/>
	<h2 id="technical">Technical information</h2>
	
	<p> <span style="color:red;">ADVANCED</span> The cache consists of
	compressed files containing listrefs of serialised objects. These objects
	are initially created from the database as if using the Ensembl API
	normally. In order to reduce the size of the cache and allow the
	serialisation to occur, some changes are made to the objects before they are
	dumped to disk. This means that they will not behave in exactly the same way
	as an object retrieved from the database when writing, for example, a plugin
	that uses the cache. </p>
	
	<p>The following hash keys are deleted from each transcript object: </p>
	
	<ul>
		<li><b>analysis</b></li>
		<li><b>created_date</b></li>
		<li><b>dbentries</b> : this contains the external references retrieved
		when calling $transcript->get_all_DBEntries(); hence this call
		on a cached object will return no entries</li>
		<li><b>description</b></li>
		<li><b>display_xref</b></li>
		<li><b>edits_enabled</b></li>
		<li><b>external_db</b></li>
		<li><b>external_display_name</b></li>
		<li><b>external_name</b></li>
		<li><b>external_status</b></li>
		<li><b>is_current</b></li>
		<li><b>modified_date</b></li>
		<li><b>status</b></li>
		<li><b>transcript_mapper</b> : used to convert between genomic, cdna,
		cds and protein coordinates. A copy of this is cached separately
		by the VEP as
		<pre class="code">$transcript->{_variation_effect_feature_cache}->{mapper}</pre>
		</li>
	</ul>
	
	<p> As mentioned above, a special hash key "_variation_effect_feature_cache"
	is created on the transcript object and used to cache things used by the VEP
	in predicting consequences, things which might otherwise have to be fetched
	from the database. Some of these are stored in place of equivalent keys that
	are deleted as described above. The following keys and data are stored: </p>
	
	<ul>
		<li><b>introns</b> : listref of intron objects for the transcript. The adaptor,
		analysis, dbID, next, prev and seqname keys are stripped from each
		intron object</li>
		<li><b>translateable_seq</b> : as returned by
		<pre class="code">$transcript->translateable_seq</pre></li>
		<li><b>mapper</b> : transcript mapper as described above</li>
		<li><b>peptide</b> : the translated sequence as a string, as returned by
		<pre class="code">$transcript->translate->seq</pre></li>
		<li><b>protein_features</b> : protein domains for the transcript's translation
		as returned by
		<pre class="code">$transcript->translation->get_all_ProteinFeatures</pre>
		Each protein feature is stripped of all keys but: start, end, analysis,
		hseqname</li>
		<li><b>codon_table</b> : the codon table ID used to translate the transcript,
		as returned by
		<pre class="code">$transcript->slice->get_all_Attributes('codon_table')->[0]</pre></li>
		<li><b>protein_function_predictions</b> : a hashref containing the keys "sift"
		and "polyphen"; each one contains a protein function prediction matrix
		as returned by e.g.
		<pre class="code">$protein_function_prediction_matrix_adaptor->fetch_by_analysis_translation_md5('sift', md5_hex($transcript-{_variation_effect_feature_cache}->{peptide}))</pre></li>
	</ul>
	
	<p> Similarly, some further data is cached directly on the transcript object
	under the following keys: </p>
	
	<ul>
		<li><b>_gene</b> : gene object. This object has all keys but the following
		deleted: start, end, strand, stable_id</li>
		<li><b>_gene_symbol</b> : the gene symbol</li>
		<li><b>_ccds</b> : the CCDS identifier for the transcript</li>
		<li><b>_refseq</b> : the "NM" RefSeq mRNA identifier for the transcript</li>
		<li><b>_protein</b> : the Ensembl stable identifier of the translation</li>
	</ul>
</div>

</body>
</html>
