
1- code API needed and executable
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bioperl-live
ensembl
ensembl-compara

executables
~~~~~~~~~~~
blastall
	using /usr/local/ensembl/bin/blastall

mcl (source can be obtained from http://micans.org/mcl/src/)
	using /nfs/acari/avilella/bin/mcxdeblast
	using /nfs/acari/avilella/bin/mcxassemble
	using /nfs/acari/avilella/bin/mcx
	using /nfs/acari/avilella/bin/mcl

2- Choose a working directory with enough disk space
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The family pipeline takes several GB of space (5GB should be sufficient). (df -k)

mkdir -p /lustre/scratch1/ensembl/lg4/families/family_54
cd /lustre/scratch1/ensembl/lg4/families/family_54
mkdir tmp fasta blast_in blast_out blast_raw mcl muscle clustalw_mpi

3- Loading in and dumping from compara the peptides
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The loading of ensembl peptides/genes and uniprot is now done as a common trunk with the gene homology pipeline.
# The loading process will identify redundant proteins using a MySQL index trick and assign to them the same 
# sequence_id. Very clever indeed!

# Before loading, make sure that in each core db:
# a) stable ids are in (look in tables 'exon_stable_id', 'translation_stable_id', 'transcript_stable_id' 
#    and 'gene_stable_id')

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_54" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select * from exon_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from translation_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from transcript_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from gene_stable_id limit 10"; echo "---"; done | less

# b) species data in 'meta' table up to date

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_54" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select * from meta" | grep species; echo "---"; done | less

# c) check the gene type e.g. pseudogene or RNA that you don't want to load and update the filter out condition if necessary

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_54" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select count(*) as number, biotype from gene group by biotype order by number desc"; echo "---"; done | less

# NB: need to add something here on how to load or a reference to homology documentation

# The dumping is done with ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl script.
# Don't use -noX or nosplit, use the default setting. The dumping process will dump only one version of each sequence,
# so no redundancy is expected in the fasta file.

# Go to the fasta dir
# Make it faster for big files in lsf
# lfs setstripe fasta 0 -1 -1
# cd fasta

# Or move it to (depending on the blast filesystem services you've got)
# mkdir -p /data/blastdb/Ensembl/family_54/fasta
# cd /data/blastdb/Ensembl/family_54/fasta

# Takes about 2 minutes
perl ~avilella/src/ensembl_main/ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl -conf /lustre/work1/ensembl/avilella/hive/avilella_compara_homology_54/genetree_all.conf --noredundancy -fasta metazoa_54.pep > metazoa_54.pep.err 2>&1 &

# or if you don't have the hive conf file
perl ~avilella/src/ensembl_main/ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl --dbhost compara2 --dbport 5316 --dbuser ensro --dbname avilella_compara_homology_54 --noredundancy --fasta metazoa_54.pep > metazoa_54.pep.err 2>&1 &

grep '>' metazoa_54.pep | wc -l
#v54 2188240
#v5? 2023775
#v51 1811409
#v50 1695699
#v49 1653108
#v48 1520968

4- Format file for blast
   ~~~~~~~~~~~~~~~~~~~~~

# Takes about 16 seconds for rel54
fastaindex metazoa_54.pep metazoa_54.index

# Takes about 5 minutes
# FIXME: a full path to formatdb should be given to avoid difference in versions
bsub -o /dev/null -q yesterday 'formatdb -p T -l metazoa_54.pep.formatdb.log -i metazoa_54.pep'

# check metazoa_54.pep.formatdb.log if it is ok delete it

# Formatted 2023775 sequences in volume 0

rm -f metazoa_54.pep.formatdb.log

# Create the index file for future run of mcl

# Takes about 4 seconds
awk 'BEGIN {idx=0} {print idx,$1;idx++}' metazoa_54.index > metazoa_54.tab
#
# NB: it is important to make sure the process above has completed
# and we have as many entries in .tab file as in .index file

5- Prepare files to run blastp
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd /lustre/scratch1/ensembl/lg4/families/family_54/blast_in

# Distribute peptide ids in several files. Each of them will contain 100 ids,
# and would correspond to one blastp job.

# Takes about 1 minute
perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/SplitPeptides.pl -maxids 250 ../fasta/metazoa_54.index

#   The created files are named: PeptideSet.1, PeptideSet.2, ..., PeptideSet.n
#   so that they are suitable for LSF job array creation. 
 

6- Run blastp with in a LSF jobs array
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# For info on jobs array, see
# http://www.sanger.ac.uk/campus/IT/ISG/lsf/job-arrays.shtml
# 
# NB: not done yet, think about putting out the SEG filter in blastp as we do for homologous genepairs, not sure
# that is a good idea. Replace SEG by CAST filtering.
# 
#  The script used to run individual blastp is
#  ensembl-compara/scripts/family/LaunchBlast.pl
# 
#  At the beginning of the script, you may need to update few lines that specifie the path
#  for the executable to be used
# 
# my $blast_executable
# my $fastafetch_executable
# my $blast_parser_executable

ls ../blast_in |wc -l
# v54 8753
# v5? 8032
# v51 7246
# v50 6783
# v49 6613
# v48 6084

# will tell you how many jobs have to be run. Just have a try with one to make sure everything is ok.
#
# It is better to place the output files in a different directory to reduce the burden on the filesystem.
# (The fewer files per directory the better).

# BDir /data/blastdb/Ensembl/family_54/fasta
# Ldir /lustre/scratch1/ensembl/lg4/families/family_54/fasta

# lg4: the following looks like an important omission:
#      But I wonder if the /data/blastdb/Ensembl/family_xx/fasta directory was needed in the first place?
#
# cp /data/blastdb/Ensembl/family_54/fasta/* /lustre/scratch1/ensembl/lg4/families/family_54/fasta/

# LaunchBlast will run like this: system("/usr/local/ensembl/bin/blastall -d $fastadb -i $qy_file -p blastp -e 0.00001 -v 250 -b 0 > $blast_file");
# where:
#   -e  Expectation value (E) [Real]
#   -v  Number of database sequences to show one-line descriptions for (V) [Integer]
#   -b  Number of database sequence to show alignments for (B) [Integer]

# This will run the first one to check if everything is working properly -- you can use "strace -p pid" to inspect your job in the cluster node

echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -bmdir /software/ensembl/compara/blast-2.2.6/data -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp"[1]" -o ../blast_out/PeptideSet.%I.out

# Check that the BLASTMAT points to /usr/local/ensembl/data/blastmat

echo $BLASTMAT

# When it is complete, you should get 2 new files

../blast_out/PeptideSet.1.out
../blast_raw/PeptideSet.1.raw.gz

# The first is the STDOUT from LSF. The latter is the blastp output parsed (and zipped)
# in the suitable format needed for the following steps.

# To check if the job finished properly

cd ../blast_out
ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done|awk '{print $2}'|sort |uniq -c

# That gives you the number of jobs "Done" and "Exited" if any.

# Then run the whole lot of jobs

# Look for the last PeptideSet.NNNN
ls | awk -F\. '{print $2}' | sort -n | tail

# This will run the rest of the jobs up to 8753
cd ../blast_in
echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -bmdir /software/ensembl/compara/blast-2.2.6/data -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp"[2-8753]" -o ../blast_out/PeptideSet.%I.out

# Rerun the failed jobs in ../blast_out.

cd ../blast_out

ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done > ../job_status

grep Exited ../job_status | awk 'BEGIN {FS="."} {print $2}' | sort -n -u >../first_batch.ids

# create the compressed list of ids to be used by bjobs:
awk 'BEGIN {s=0;e=0;i=1;c=""} s==0 {s=$1;e=$1;c=s;next} $1==e+1 {e=$1;c=s"-"e;next} $1>e+1 {printf c ((i%15)?",":"\n");s=$1;e=$1;c=s;i++;next} END {print c}' ../first_batch.ids >../first_batch_ids.collapsed

cd ..

# Because this only checks the out files, you can resubmit safely even if you still have running jobs, that haven't produced an out file yet:
grep Exited job_status |awk '{print $1}'|while read i;do rm -f blast_out/$i;done

cat first_batch_ids.collapsed | while read i;do echo "echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -bmdir /software/ensembl/compara/blast-2.2.6/data -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub

# Then move to blast_in and resubmit the failed jobs

cd blast_in
bash rebsub


# Sometimes you get jobs that fail because they failed previously and you forgot to remove the output files.
# Check if you have any of such files:

cd ..
grep -lr 'Job already finished' blast_out >second_batch.filenames

# If the file is empty - just go to step 8. Otherwise:

# create the list of the ids:
awk 'BEGIN {FS="."} {print $2}' second_batch.filenames | sort -n -u >second_batch.ids

# compress it:
awk 'BEGIN {s=0;e=0;i=1;c=""} s==0 {s=$1;e=$1;c=s;next} $1==e+1 {e=$1;c=s"-"e;next} $1>e+1 {printf c ((i%15)?",":"\n");s=$1;e=$1;c=s;i++;next} END {print c}' second_batch.ids >second_batch_ids.collapsed

# actually remove the offending files (both out- and raw-files) (may want a while-read-do-rm solution for longer files?):
rm `cat second_batch.filenames`
rm `cat second_batch.filenames | sed "s/blast_out/blast_raw/" | sed "s/.out/.raw.gz/"`

# re-create the submission commands:
cat second_batch_ids.collapsed | while read i;do echo "echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -bmdir /software/ensembl/compara/blast-2.2.6/data -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub2

# actually submit the jobs:
cd blast_in
bash rebsub2


# SOMETIMES you get some jobs disappearing completely, without leaving any traces (including the .out files).
# That's the property you can use to identify them:
cd ..
ls blast_in | perl -lane ' unless( -e "blast_out/$F[0].out") { $F[0]=~s/PeptideSet\.//; print $F[0]; }' | sort -n -u >missing.ids

# again, compress the list:
awk 'BEGIN {s=0;e=0;i=1;c=""} s==0 {s=$1;e=$1;c=s;next} $1==e+1 {e=$1;c=s"-"e;next} $1>e+1 {printf c ((i%15)?",":"\n");s=$1;e=$1;c=s;i++;next} END {print c}' missing.ids >missing_ids.collapsed

# re-create the submission commands:
cat missing_ids.collapsed | while read i;do echo "echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -bmdir /software/ensembl/compara/blast-2.2.6/data -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub3

# actually submit the jobs:
cd blast_in
bash rebsub3

8- Build the matrix needed by mcl and check it for symmetry
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../blast_raw

# Takes about 8-10 minutes, do on a farm node
# Took 25 seconds with stijn parameters
export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err 'find -name "*.raw.gz"|xargs gunzip -c > ../mcl/family_54.raw'

# To keep the order of the files you can do this instead:
# find -name '*.raw.gz' | sort -t\. -k3 -n | xargs gunzip -c > ../mcl/family_54.raw

cd ../mcl

# create a symlink to /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab

ln -s /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab family_54.tab

# create a family_54.hdr header file,
# The dimensions should be the number of peptides. That can be obtained by

# wc -l family_54.raw
# 2188240 family_54.raw
# lg4@bc-9-1-03:/lustre/scratch1/ensembl/lg4/families/family_54/mcl$ wc -l family_54.tab
# 2188240 family_54.tab

wc -l family_54.tab
# v54 2188240 family_54.tab
# v5? 2023775 family_5?.tab
# v51 1811409 family_51.tab
# v50 1695699 family_50.tab
# v49 1653108 family_49.tab
# v48 1520968 family_48.tab


cat > family_54.hdr
(mclheader
mcltype matrix
dimensions 2188240x2188240
)

# This takes not 30 min but about 8-10 minutes now that we have bigmem
# fast nodes, and will generate a family_54.bin matrix file.
# export TIMESTAMP=`date +2%3y%m%d_%H%M%S`
# bsub -o $TIMESTAMP.out -e $TIMESTAMP.err '~avilella/src/ensembl_main/ensembl-compara/scripts/family/mcxassemble.sh family_54'

# lg4: why should we bsub the script to the farm, if it has its own bsub inside?

# 50 min -- tcx file using lots of memory in turing -- bin is machine-dependent -- tcx is cross-machine compatible
export TIMESTAMP=`date +2%3y%m%d_%H%M%S`
bsub -o $TIMESTAMP.out -e $TIMESTAMP.err '~avilella/src/ensembl_main/ensembl-compara/scripts/family/mcxassemble.sh.tcx family_54'

cd /lustre/scratch1/ensembl/lg4/families/family_54/mcl
# The home directory is visible to turing, so it's more convenient and doesn't take that much space
mkdir ~/family_54/
#cp -f family_54.hdr ~/family_54/
#cp -f family_54.tab ~/family_54/
mv family_54.tcx ~/family_54/

# Check that everything is all right in family_54.mcxassemble.err

# We don't need the raw file anymore and as it takes quite a lot of space, delete it.

rm -f family_54.raw

9- Run mcl
   ~~~~~~~

This step uses turing which has 192Gb of memory :))) and 16 CPUs. As mcl can be multi-threaded, it is very useful.

Try to use 12 cpus, less if available in the hugemem queue, try to use lots of RAM, less if available:

for n in `seq 12 -1 1`
do
        for mem in `seq 95000 -20000 35000`
        do
                sleep 1
                hmem=$(($mem * 1000))
                # old method
                # export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err -C0 -R "select[ncpus>=$n && mem>$mem] rusage[mem=$mem] span[hosts=1]" -M$hmem -q hugemem -n $n "/nfs/acari/avilella/src/mcl-08-152/src/shmcl/mcl ~/family_54/family_54.tcx -I 2.1 -t $n -P 10000 -S 1000 -R 1260 -pct 90 -o ~/family_54/family_54.mcl.turing.pct90.$n.$mem.$TIMESTAMP"
                # new method
                export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err -C0 -R "select[ncpus>=$n && mem>$mem] rusage[mem=$mem] span[hosts=1]" -M$hmem -q hugemem -n $n "/nfs/acari/avilella/src/mcl-08-152/src/shmcl/mcl ~/family_54/family_54.tcx -I 2.1 -t $n -tf 'gq(50)' -scheme 6 -o ~/family_54/family_54.mcl.turing.gq50.6.$n.$mem.$TIMESTAMP"
                done
done

# Once you have one of the jobs running, kill the remaining pending jobs with "bkill jobid".

# turing old method (v48 and before)
# export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err -C0 -R 'select[ncpus>=8 && mem>10000 && type==LINUX64] rusage[mem=10000] span[hosts=1]' -q hugemem -n 8 -f "family_54.bin > /tmp/family_54.bin" -f "family_54.mcl < /tmp/family_54.mcl" -o mcl.out /nfs/acari/abel/bin/arch-ia64/mcl /tmp/family_54.bin -I 2.1 -t 8 -P 10000 -S 1000 -R 1260 -pct 90 -o /tmp/family_54.mcl

# NB: whenever you have finished running mcl (maybe with different parameters), don't forget 
# to delete /tmp/family_50.* from aristotle /tmp (a shell script having the flavour of 
# mcxassemble.sh or mcx.sh could do it automatically...not very useful though if several mcl run have to be tested)

10- Load into compara database
    ~~~~~~~~~~~~~~~~~~~~~~~~~

# You'll need a compara database set up, with genome_db, taxon, and method_link tables prefilled.

# Edit the reg_conf.50.pl to point to the compara_homology db
/lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf_54.pl

# Your reg_conf.pl should be something like

use strict;
use Bio::EnsEMBL::Utils::ConfigRegistry;
use Bio::EnsEMBL::Compara::DBSQL::DBAdaptor;

new Bio::EnsEMBL::Compara::DBSQL::DBAdaptor(-host => 'compara2',
                                            -user => 'ensadmin',
                                            -pass => 'ensembl',
                                            -port => 5316,
                                            -species => 'compara54',
                                            -dbname => 'avilella_compara_homology_54');
1;

# This takes around an hour, and you can not do anything else before the loading is completed.

nohup ~avilella/src/ensembl_main/ensembl-compara/scripts/family/parse_mcl.pl --dbname compara54 --reg_conf /lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf_54.pl family_54.tab family_54.mcl -prefix fam54 > family_54.description 2> family_54.description.err &

# To save space,

bsub 'gzip family_54.mcl'

11- Run mafft over all the families
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# !!!Step 13 should be run also at the same time. It is not dependant on multiple alignments.

mysql -hcompara2 -P5316 -uensro avilella_compara_homology_54 -e "select count(*), family_id from family_member where cigar_line IS NULL group by family_id having count(*)>1" | wc -l
# v54 88800
# v5? 80681
# v51 74656
# v50 72676
# v49 6413
# v48 44852
# v47 43834

cd /lustre/scratch1/ensembl/lg4/families/family_54/

# Get a list of all the family ids with more than one member. If you get it in random order, then the size of each id will be randomly spread in the list, and the jobs
# will be more randomly distributed in terms of CPU time
mysql -hcompara2 -P5316 -uensro avilella_compara_homology_54 -N -e "select family_id from family_member group by family_id having count(*)>1 order by RAND()" > family_ids_rand.txt

# I use a generic hive database for uploading the jobs. Each job is a LaunchMafft_batch.pl iwth a family id in the list
perl /nfs/acari/avilella/src/ensembl_main/ensembl-personal/avilella/hive/cmd_hive.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -input_id 'perl /nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchMafftOnFamilies_batch.pl -h compara2 -p 5316 -db avilella_compara_homology_54 -u ensadmin -ps ensembl -f $inputfile -n 1 -s' -inputfile /lustre/scratch1/ensembl/lg4/families/family_54/family_ids_rand.txt -hive_capacity 200 -batch_size 5 -logic_name family_mafft_54_2

export PATH=$PATH:/nfs/acari/avilella/src/ensembl_main/ensembl-hive/scripts/
# export PATH=$PATH:/nfs/team71/analysis/lg4/work/ensembl-hive/scripts
beekeeper.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -sync

beekeeper.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -lsf_options '-R"select[mycompara2<500] rusage[mycompara2=10:duration=10:decay=1]"' -lifespan 1200 -loop -logic_name family_mafft_54_2

# The last ~1000 should be done with lots of memory:
beekeeper.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -lsf_options '-R"select[mycompara2<500 && mem>15000] rusage[mycompara2=10:duration=10:decay=1:mem=15000]" -M15000000' -lifespan 1200 -loop -logic_name family_mafft_54_2
# in case of rel54 only 7 first (biggest) families needed to be run with more memory
# (and were run directly, bypassing the LSF, on turing)


12- Insert the redundant proteins in the compara db
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../fasta

First, set all singletons cigar_line to the length(m.sequence) + "M", because some singletons will disappear with the addition of redundant sequences.

mysql -h compara2 -u ensro -P5316 -N -e "select family_id,count(*) as count from family_member group by family_id having count=1" avilella_compara_homology_54 | awk '{print "select family_id, length(s.sequence) from member m,family_member fm, sequence s where fm.member_id=m.member_id and fm.family_id="$1" and s.sequence_id = m.sequence_id;"}'|mysql -h compara2 -u ensro -P5316 -N avilella_compara_homology_54 |awk '{print "update family_member set cigar_line=\""$2"M\" where family_id="$1";"}'|sort -u > update_singletons_cigar_line.sql
# took 52 minutes for rel54

mysql -h compara2 -uensadmin -pensembl -P5316 avilella_compara_homology_54 < update_singletons_cigar_line.sql
# took 59 minutes for rel54

perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/InsertRedundantPeptidesAndGenesInFamilies.pl --reg_conf /lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf_54.pl --dbname compara54 > Redundancy_and_Genes_load.err 2>&1 &
# took 86 minutes for rel54

# IMPORTANT: add healthcheck about NULL cigar_line
mysql -hcompara2 -P5316 -uensro avilella_compara_homology_54 -e "select m.source_name,count(*) from family_member fm, member m where fm.member_id=m.member_id and fm.cigar_line is NULL group by m.source_name"

# This should return count for ENSEMBLGENE;

mysql -hcompara2 -P5316 -uensro avilella_compara_homology_54 -e "select fm.family_id,count(*) from family_member fm, member m where fm.member_id=m.member_id and fm.cigar_line is NULL and m.source_name!='ENSEMBLGENE' group by fm.family_id"

This should only list the families for which multiple alignment could not be run.

# E.g.:
# +-----------+----------+
# | family_id | count(*) |
# +-----------+----------+
# |       178 |      691 | 
# +-----------+----------+

13- Generates the family descriptions
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    This part really sucks and need a profound rethinking to get the description more clean and consistant.

       ensembl-compara/scripts/family/consensifier.pl 
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       # This step takes approx 2 hours total
       cd mcl
       perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/consensifier.pl -d "Uniprot/SWISSPROT" family_54.description > family_54.description.SWISSPROT-consensus 2> family_54.description.SWISSPROT-consensus.err
# took 28 mins in rel54

       perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/consensifier.pl -d "Uniprot/SPTREMBL" family_54.description > family_54.description.SPTREMBL-consensus 2> family_54.description.SPTREMBL-consensus.err
# took 8 hours in rel54

       ensembl-compara/scripts/family/assemble-consensus.pl
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/assemble-consensus.pl family_54.description family_54.description.SWISSPROT-consensus family_54.description.SPTREMBL-consensus  > family_54.description-consensus 2> family_54.description-consensus.err
# took 4 minutes in rel54


# update the family description in ensembl_family_54 with the data in family_54.description-consensus using ensembl-compara/scripts/family/LoadDescriptionInFamily.pl 
# (Use the same reg_cong.pl as in step 11)

perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/LoadDescriptionInFamily.pl --reg_conf /lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf_54.pl --dbname compara54 family_54.description-consensus
# took 55 minutes in rel54

