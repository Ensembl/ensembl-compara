#!/usr/bin/env python3
# See the NOTICE file distributed with this work for additional information
# regarding copyright ownership.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Generate stats for the given HAL file."""

from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter
from collections import Counter
import csv
import itertools
import logging
import math
from multiprocessing import Pool
from operator import itemgetter
from pathlib import Path
import re
import subprocess
from tempfile import SpooledTemporaryFile
from typing import Dict, List, TextIO, Union


logging.basicConfig(format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


def hal_genomic_coverage(hal_path: Union[Path, str], ref_genome: str, ref_sequence: str,
                         no_ancestors: bool = False, step: int = 1) -> Dict:
    """Uses halAlignmentDepth to get genomic coverage for the given genome and sequence.

    Args:
        hal_path: Input HAL file.
        ref_genome: Reference genome against which alignment depth is calculated.
        ref_sequence: Sequence in reference genome for which alignment depth is calculated.
        no_ancestors: Exclude ancestral genomes from depth calculations.
        step: Step size.

    Returns:
        Nested dictionary of coverage stats, with the key being the sequence name,
        and the value being a dictionary of coverage stats for that sequence.

    """
    logger.info("Getting genomic coverage for sequence '%s' of genome '%s' ...", ref_sequence, ref_genome)

    command = [
        "halAlignmentDepth",
        hal_path,
        ref_genome,
        "--refSequence", ref_sequence,
        "--step", str(step)
    ]

    if no_ancestors:
        command.append("--noAncestors")

    rollover_limit = 1_048_576
    with SpooledTemporaryFile(max_size=rollover_limit, mode="w+t") as tmp_file_obj:

        try:
            subprocess.run(command, stdout=tmp_file_obj, text=True, encoding="ascii", check=True)
        except subprocess.CalledProcessError as exc:
            status_type = "exit code" if exc.returncode > 0 else "signal"
            logger.exception("halAlignmentDepth terminated with %s %d for sequence '%s' of genome '%s'",
                             status_type, abs(exc.returncode), ref_sequence, ref_genome)
            raise

        tmp_file_obj.flush()
        tmp_file_obj.seek(0)
        result_part = load_genomic_coverage_wiggle(tmp_file_obj)

    return result_part


def load_genome_names(hal_file: Union[Path, str], include_ancestors: bool = False) -> List[str]:
    """Load genome names from an input HAL file.

    Args:
        hal_file: Input HAL file.
        include_ancestors: Include ancestral genomes in the returned list of genome names.

    Returns:
        Sorted list of genome names.

    """
    ancestor_re = re.compile("Anc[0-9]+")

    cmd = ["halStats", "--genomes", hal_file]
    process = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding="ascii")
    hal_genome_names = process.stdout.rstrip().split(" ")

    if not include_ancestors:
        hal_genome_names = [x for x in hal_genome_names if not ancestor_re.fullmatch(x)]

    return sorted(hal_genome_names)


def load_genomic_coverage_wiggle(wiggle_file_obj: Union[SpooledTemporaryFile, TextIO]) -> Dict:
    """Load data form wiggle file generated by halAlignmentDepth.

    Args:
        wiggle_file_obj: Input wiggle file object.

    Returns:
        Nested dictionary of coverage stats, with the key being the sequence name,
        and the value being a dictionary of coverage stats for that sequence.

    """
    declaration_line_re = re.compile(
        r"fixedStep chrom=(?P<chrom>\S+) start=(?P<start>[0-9]+) step=(?P<step>[0-9]+)\s*"
    )

    cov_stats = {}
    curr_seq_name = None
    for line in wiggle_file_obj:
        try:
            aligned_genome_count = int(line)
        except ValueError as exc:

            if (match := declaration_line_re.fullmatch(line)):
                curr_seq_name = match["chrom"]
                if curr_seq_name in cov_stats:
                    raise ValueError(
                        f"multiple occurrences of sequence '{curr_seq_name}' found") from exc
                cov_stats[curr_seq_name] = {
                    "site_coverage_bp": 0,
                    "sites_sampled_bp": 0,
                    "start": int(match["start"]),
                    "step": int(match["step"]),
                }
            elif line.startswith("variableStep"):
                raise ValueError("variableStep blocks not supported") from exc
            else:
                raise ValueError(f"failed to parse wiggle line: {line}") from exc

        else:
            if aligned_genome_count > 0:
                cov_stats[curr_seq_name]["site_coverage_bp"] += 1
            cov_stats[curr_seq_name]["sites_sampled_bp"] += 1

    return cov_stats


def load_seq_lengths(hal_file: Union[Path, str], genome_name: str) -> Dict[str, int]:
    """Load sequence lengths from an input HAL file.

    Args:
        hal_file: Input HAL file.
        genome_name: Name of the HAL genome for which sequence lengths should be obtained.

    Returns:
        Dictionary mapping sequence names to their lengths.

    """
    cmd = ["halStats", "--chromSizes", genome_name, hal_file]
    process = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding="ascii")

    seq_lengths = {}
    for line in process.stdout.splitlines():
        seq_name, seq_length = line.rstrip().split("\t")
        seq_lengths[seq_name] = int(seq_length)

    return seq_lengths


def main() -> None:
    """Main HAL MSA stats function."""

    parser = ArgumentParser(description=__doc__, formatter_class=ArgumentDefaultsHelpFormatter)
    parser.add_argument("in_hal_path",
                        help="Input HAL file.")
    parser.add_argument("out_tsv_path",
                        help="Output TSV file.")
    parser.add_argument("--genomes", metavar="STR", default="all",
                        help="Comma-separated list of genomes for which"
                             " genomic coverage is calculated.")
    parser.add_argument("--include-ancestors", action="store_true",
                        help="Include ancestral genomes in stats output.")
    parser.add_argument("--step-size", metavar="INT", type=int, default=1,
                        help="Size of step between coverage sample positions.")
    parser.add_argument("--min-seq-length", metavar="INT", type=int, default=1,
                        help="Minimum length of sequences to consider.")
    parser.add_argument("-n", "--num-procs", metavar="INT", default=1, type=int,
                        help="Number of parallel processes to use.")

    args = parser.parse_args()


    logger.info("Getting alignment stats from HAL file '%s' ...", args.in_hal_path)

    no_ancestors = not args.include_ancestors

    avail_genomes = load_genome_names(args.in_hal_path, include_ancestors=args.include_ancestors)

    if args.genomes == "all":
        genome_names = avail_genomes
    else:
        genome_name_counts = Counter(args.genomes.split(","))

        dup_genome_names = [x for x, n in genome_name_counts.items() if n > 1]
        if dup_genome_names:
            raise ValueError(f"duplicate genome names: {','.join(dup_genome_names)}")

        unk_genome_names = set(genome_name_counts.keys()) - set(avail_genomes)
        if unk_genome_names:
            raise ValueError(f"unknown genome names: {','.join(unk_genome_names)}")

        genome_names = sorted(genome_name_counts.keys())


    stats = {}
    for genome_name in genome_names:
        logger.info("Getting stats for HAL genome '%s' ...", genome_name)
        seq_lengths = load_seq_lengths(args.in_hal_path, genome_name)

        chr_by_length_desc = []
        for seq_name, seq_length in sorted(seq_lengths.items(), key=itemgetter(1), reverse=True):
            if seq_length < args.min_seq_length:
                logger.warning("Length of HAL sequence '%s' (%d) is shorter"
                               " than min_seq_length (%d), skipping ...",
                               seq_name, seq_length, args.min_seq_length)
                continue
            chr_by_length_desc.append(seq_name)

        logger.info("Preparing to get stats for %d sequences of genome '%s' ...",
                    len(chr_by_length_desc), genome_name)

        param_sets = []
        for seq_name in chr_by_length_desc:
            param_sets.append((args.in_hal_path, genome_name, seq_name,
                               no_ancestors, args.step_size))

        with Pool(processes=args.num_procs) as pool:
            result_parts = pool.starmap(hal_genomic_coverage, param_sets, chunksize=1)

        result = dict(itertools.chain.from_iterable((x.items() for x in result_parts)))

        genome_stats: Dict = {"site_coverage_bp": 0, "sites_sampled_bp": 0}
        for seq_name, seq_stats in result.items():

            obs_sampled_bp = seq_stats["sites_sampled_bp"]
            exp_sampled_bp = math.floor(seq_lengths[seq_name] / seq_stats["step"]) + 1
            if obs_sampled_bp != exp_sampled_bp:
                raise ValueError(f"site-count mismatch for '{seq_name}':"
                                 f" {obs_sampled_bp} vs {exp_sampled_bp}")

            genome_stats["site_coverage_bp"] += seq_stats["site_coverage_bp"]
            genome_stats["sites_sampled_bp"] += seq_stats["sites_sampled_bp"]

        genome_stats["sequences_checked_bp"] = sum(seq_lengths[k] for k in chr_by_length_desc)
        genome_stats["genome_length_bp"] = sum(seq_lengths.values())
        try:
            genome_stats["site_coverage_pct"] = 100.0 * (
                genome_stats["site_coverage_bp"] / genome_stats["sites_sampled_bp"])
        except ZeroDivisionError:
            genome_stats["site_coverage_pct"] = float("nan")

        stats[genome_name] = genome_stats


    out_col_names = [
        "genome_name",
        "genome_length_bp",
        "sequences_checked_bp",
        "sites_sampled_bp",
        "site_coverage_bp",
        "site_coverage_pct",
    ]

    with open(args.out_tsv_path, "w") as out_file_obj:
        writer = csv.writer(out_file_obj, delimiter="\t", lineterminator="\n")
        writer.writerow(out_col_names)
        for genome_name, genome_stats in stats.items():
            writer.writerow([
                genome_name,
                genome_stats["genome_length_bp"],
                genome_stats["sequences_checked_bp"],
                genome_stats["sites_sampled_bp"],
                genome_stats["site_coverage_bp"],
                f"{genome_stats['site_coverage_pct']:.3f}",
            ])

    logger.info("Done.")


if __name__ == "__main__":
    main()
